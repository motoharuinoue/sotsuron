\chapter{はじめに}

\begin{enumerate}

  \item ファッションについて

  ファッションというのは、自己表現の一つである。
  近年では店舗に足を運ばなくても商品を購入できる通信販売が人気を博している。
  ZOZOTOWNを運営するスタートトゥデイ（株）は営業利益率が前年比11.6\verb|%|と大幅に上昇している。

  \item システムの必要性

  近年ではSiri等の音声による検索システムが開発されている。
  音声検索では口語の文章を分析する必要がある。
  本研究では感性語を画像と文章の媒介として用いることで口語文における検索精度向上の可能性を模索した。
  \\
  　通販サイトは実際に試着できるわけではないので、コーディネートまでは分からない。
  購入した商品が自分の持っている服に合わないという場合が多々ある。
  ユーザの所持品を考慮する必要性あり。

  \item CNNの能力について

  画像分類タスクを始めとする様々なタスクで突出した精度を誇る。
  ILSVRC 2015では人間を超えたと言われている。

  \item word2vecの能力について

  word2vecは単語を分散表現にすることで、単語同士のベクトル演算を可能にする。
  また、cos類似度をとることによって、単語間の距離を測ることも可能である。

  \item 事前学習の有効性

  Donahue, Razavian, Sermanetらの研究では事前学習したCNNモデルの特徴は様々な画像分類タスクに転用することができる包括的な画像表現であることを実証した。
  Weiらの研究では、事前学習させたモデルにさらに検証に用いるデータの一部を用いてファインチューニングさせることでさらに精度が向上することを発見した。

  \item 既存研究

  ファッションアイテムの検索システムとしては、アイテム画像を入力して似たアイテムの画像を表示する研究や、
  画像に加えて属性情報を考慮して柔軟に検索する研究が行われている。しかしこれらの検索方法は参考画像を必要としており、文章のみの入力に対応できない。
  そこで本研究では文章のみでアイテム画像を検索するシステムを構築する。
  また、アイテムを組み合わせてコーディネートを作成するシステムが開発されているが、感性語を考慮していない。
  そこで本研究では感性語を考慮した新たなコーディネートシステムを提案する。

  \item システムの概要
  \begin{enumerate}
      \item 既存のCNNモデルをDeepFashionデータセットのカテゴリー分類タスクで事前学習。
      その後SENSY（株）から提供された検証用データの一部を用いてファインチューニング。

      \item アイテム画像をCNNに入力し、感性語を取得。
      逆に文章を入力し、アイテム画像を取得。

      \item アイテムの組み合わせに対しても、画像から感性語を取得。逆に文章からアイテムの組み合わせ画像を取得。

      \item 画像と感性語の関連性に着目し、アイテム画像から似合う他のファッションアイテムの組み合わせを提示。
  \end{enumerate}

  \item 評価実験

  画像から感性語を取得するタスクでは、出力した感性語が実際のキャプションに含まれている割合を検証。
  また主観評価実験で、得られた感性語が画像にふさわしいかどうかを検証。
  文章から画像を取得するタスクでは、主観評価実験で入力文にふさわしい画像が出力されているかを検証。
  提案システムに関しては、提案されたコーディネートが自然かどうかを検証。

  \item 論文の構成
  第２章では提案システムについて、第３章では評価実験、第４章で今後の展望、第５章で結論を述べる。




\end{enumerate}
